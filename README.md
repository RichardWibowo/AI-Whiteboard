# AI-Whiteboard

[![GitHub Release Date](https://img.shields.io/github/release-date/RichardWibowo/AI-Whiteboard)](https://github.com/RichardWibowo/AI-Whiteboard)
[![GitHub last commit](https://img.shields.io/github/last-commit/RichardWibowo/AI-Whiteboard)](https://github.com/RichardWibowo/AI-Whiteboard)

> Creative tool to assist online class, or at least thats the idea

welcome to my AI Whiteboard project, im using Mediapipe and openCV for this project, while Mediapipe is not really necessary, since we can hardcode it, i wanna use mediapipe to faster 
development, using Mediapipe is also beneficial for future projects, since i already made it as modular as possible.

## Why?

this project got inspired from the lack of whiteboard/blackboard in classroom, which is quite essential in a classroom, and we cannot have them in our new enviroment called _online classroom_, which is sad, and so i made this, at first i want it to track a pen on a piece of board, but it is too hard to do with the time limit as such, so i made this instead

## How?

well the full documentation is at the .ipynb file in this repo, the simplest explaination on this project is implementing Mediapie, a Live ML system developed by Google, is a high-fidelity hand and finger tracking solution. It employs machine learning (ML) to infer 21 3D landmarks of a hand from just a single frame.

so by using this i can effectively made this project to this stage, while its still not done just yet, i feel like this is enough for now 

## how it works

<p align ="center" >
  hand from webcam -> processed to get index finger and middle finger using mediapipe -> draw 
</p>

this is the most basic explainantion on how it works, for more info read the.ipynb file
 
 
